{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Select an Interpreter to start Jupyter\n",
      "\u001b[1;31mRun the following command to install 'jupyter and notebook' into the Python environment. \n",
      "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
      "\u001b[1;31mor\n",
      "\u001b[1;31mconda install jupyter notebook -U'\n",
      "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "from diffusers import StableDiffusionInstructPix2PixPipeline, EulerAncestralDiscreteScheduler\n",
    "\n",
    "model_id = \"timbrooks/instruct-pix2pix\"\n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id, torch_dtype=torch.float16, revision=\"fp16\", safety_checker=None)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)\n",
    "pipe.to(device)\n",
    "pipe.enable_attention_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "def new_forward(self, *args, **kwargs):\n",
    "    \n",
    "    print (\"\\n************FORWARD HO**************\\n\")\n",
    "\n",
    "    print(f'input tensor shape: {[arg.size() for arg in args]}')\n",
    "    print(f'kwargs: {kwargs}')\n",
    "    print(f'call stack: ')\n",
    "\n",
    "    for line in traceback.format_stack():\n",
    "        print(line.strip())\n",
    "\n",
    "    return self.text_model(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.open(\"./david.jpeg\")\n",
    "image = PIL.ImageOps.exif_transpose(image)\n",
    "image = image.convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = pipe.text_encoder.to(device)\n",
    "\n",
    "forward_method_type = type(model.forward)\n",
    "\n",
    "model.forward = forward_method_type(new_forward, model)\n",
    "\n",
    "pipe.text_encoder = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10101\n",
    "generator = torch.manual_seed(seed)\n",
    "prompt = \"make his face more smug\"\n",
    "smug = pipe(prompt, image=image, num_inference_steps=30, image_guidance_scale=1.05, generator=generator).images[0]\n",
    "smug"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ip2p2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf973059294a6b48d11a2baa325755195e4fbf9c9ca79e777e67cd898c3b0ca1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
